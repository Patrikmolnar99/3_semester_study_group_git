---
title: "Assignment 2 - Meta-analysis of pitch in schizophrenia"
author: "Riccardo Fusaroli"
date: "16/8/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(glue,
       tidyr,
       data.table,
       moments,
       tidybayes,
       tibble,
       cowplot,
       viridis,
       brms,
       rstan,
       cmdstanr,
       magrittr,
       gridExtra,
       grid,
       lattice,
       ggplot2,
       ggridges,
       ellipse,
       Rmisc, 
       dplyr, 
       "rmarkdown", 
       knitr)

pacman::p_load(tidyverse)

pacman::p_load(purr)

pacman::p_load(MCMCglmm)

pacman::p_load(readxl)
```

# Assignment 2: meta-analysis

## Questions to be answered

1.  Simulate data to setup the analysis and gain insight on the structure of the problem. Simulate one dataset of 100 studies (n of participants should follow a normal distribution with mean of 20, sd of 10, but no fewer than 10 participants), with a mean effect size of 0.4, average deviation by study of .4 and measurement error of .8. The data you get should have one row per study, with an effect size mean and standard error. Build a proper bayesian model to analyze the simulated data. Then simulate publication bias (only some of the studies you simulate are likely to be published, which?), the effect of publication bias on your estimates (re-run the model on published studies, assess the difference), and use at least one technique to assess publication bias. remember to use at least one plot to visualize your results. BONUS question: do a power/precision analysis.

2.  What is the current evidence for distinctive vocal patterns in schizophrenia? Use the data from Parola et al (2020) - <https://www.dropbox.com/s/0l9ur0gaabr80a8/Matrix_MetaAnalysis_Diagnosis_updated290719.xlsx?dl=0> - focusing on pitch variability (PITCH_F0SD). Describe the data available (studies, participants). Using the model from question 1 analyze the data, visualize and report the findings: population level effect size; how well studies reflect it; influential studies, publication bias. BONUS question: add the findings from <https://www.medrxiv.org/content/10.1101/2022.04.03.22273354v2>. BONUS question: assess the effect of task on the estimates (model comparison with baseline model)

## Question 1

### Simulation

```{r}
mean_effect <- 0.4
effect_sd <- 0.4
meas_error <- 0.8

par_mean <- 20
par_sd <- 10

n <- 100

```

```{r}
sim_studies <-
  tibble(
    study_ID = seq(1:n),
    n_participants = 
        round(rtnorm(n, mean=par_mean, sd=par_sd, lower=10))
    ) 
      
  
for (i in seq(nrow(sim_studies))){
    sim_studies$study_effect[i] <- 
      rnorm(1,mean_effect,effect_sd)
    temp <- 
      rnorm(sim_studies$n_participants[i],sim_studies$study_effect[i], meas_error)
    sim_studies$mean_effect_size[i] <- 
      mean(temp)
    sim_studies$sd_effect[i] <- 
      sd(temp)
    sim_studies$standard_error[i] <-
      sim_studies$sd_effect[i]/sqrt(sim_studies$n_participants[i])
  }


```

### Bayesian model

```{r}
model_study <- bf(mean_effect_size|se(standard_error) ~1 + (1|study_ID))
```

#### Priors

```{r}
get_prior(data = sim_studies, family = gaussian, model_study)

priors <- c(
  prior(normal(0, 0.3), class=Intercept),
  prior(normal(0, 0.3), class=sd))
```

#### Model

Only priors

```{r}
model_prior <- brm(
  model_study, 
  data = sim_studies, 
  prior = priors,
  family = gaussian,
  refresh=0,
  sample_prior = 'only',
  iter=10000,
  warmup = 1000,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
)
)

pp_check(model_prior, ndraws=100)
```

#### Fitting model

```{r}
model_prior_fit <- brm(
  model_study, 
  data = sim_studies, 
  prior = priors,
  family = gaussian,
  refresh=0,
  sample_prior = TRUE,
  iter=10000,
  warmup = 1000,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
)
)

pp_check(model_prior_fit, ndraws=100)
```

```{r}
plot(model_prior_fit)
```
```{r}
summary(model_prior_fit)
```


#### Prior posterior update check
```{r}
model_posterior <- as_draws_df(model_prior_fit)

plot1 <- ggplot(model_posterior)+
  geom_histogram(aes(prior_Intercept), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on intercept')+
  xlab('intercept')


plot2 <- ggplot(model_posterior)+
  geom_histogram(aes(prior_sd_study_ID), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(sd_study_ID__Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on standard deviation of the intercept')+
  xlab('intercept')

grid.arrange(plot1, plot2)
```


### Simulation of publication bias, the effect of publication bias on our estimate and asses the publication bias (remember to visualize our results)

```{r}
for (i in seq(nrow(sim_studies))){
  sim_studies$published[i] <-
    ifelse(abs(
      sim_studies$mean_effect_size)-(2*sim_studies$standard_error)>0 
      & sim_studies$mean_effect_size[i]>0,
      rbinom(1,1,0.9), rbinom(1,1,0.1))}

sim_studies <- sim_studies %>%
  mutate(published=as.factor(published))

pub_sim_studies <- filter(sim_studies, published==1)
```

```{r}
pub_model_prior_fit <- brm(
  model_study, 
  data = pub_sim_studies, 
  prior = priors,
  family = gaussian,
  refresh=0,
  sample_prior = TRUE,
  iter=10000,
  warmup = 1000,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
)
)

pp_check(pub_model_prior_fit, ndraws=100)
```

```{r}
plot(pub_model_prior_fit)

summary(pub_model_prior_fit)

pub_posterior <- as_draws_df(pub_model_prior_fit)
```

```{r}
pub_plot1 <- ggplot(pub_posterior)+
  geom_histogram(aes(prior_Intercept), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on intercept (published)')+
  xlab('intercept')


pub_plot2 <- ggplot(pub_posterior)+
  geom_histogram(aes(prior_sd_study_ID), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(sd_study_ID__Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on standard deviation of the intercept (published)')+
  xlab('sd')


grid.arrange(pub_plot1, pub_plot2)


```
```{r}
plot3 <- ggplot()+
  geom_histogram(aes(pub_posterior$Intercept), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(model_posterior$Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('intercept with and without the un-published studis')+
  xlab('red=without un-published, green=with un-published')


plot4 <- ggplot()+
  geom_histogram(aes(pub_posterior$sd_study_ID__Intercept), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(model_posterior$sd_study_ID__Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('standard deviation of the intercepts with and without the un-published studis')+
  xlab('red=without un-published, green=with un-published')

grid.arrange(plot3, plot4)
```

### BONUS: Power/precision analysis

## Question 2

```{r}
matrix_ma <- read_excel("Matrix_MetaAnalysis.xlsx")
```
