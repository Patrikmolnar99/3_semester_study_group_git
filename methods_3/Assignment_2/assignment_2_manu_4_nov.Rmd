---
title: "Assignment 2 - Meta-analysis of pitch in schizophrenia"
author: "Riccardo Fusaroli"
date: "16/8/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(glue,
       tidyr,
       data.table,
       moments,
       tidybayes,
       tibble,
       cowplot,
       viridis,
       brms,
       rstan,
       cmdstanr,
       magrittr,
       gridExtra,
       grid,
       lattice,
       ggplot2,
       ggridges,
       ellipse,
       Rmisc, 
       dplyr, 
       "rmarkdown", 
       knitr)

pacman::p_load(tidyverse)

pacman::p_load(purr)

pacman::p_load(MCMCglmm)

pacman::p_load(readxl)

pacman::p_load(metafor)
```

# Assignment 2: meta-analysis

## Questions to be answered

1.  Simulate data to setup the analysis and gain insight on the structure of the problem. Simulate one dataset of 100 studies (n of participants should follow a normal distribution with mean of 20, sd of 10, but no fewer than 10 participants), with a mean effect size of 0.4, average deviation by study of .4 and measurement error of .8. The data you get should have one row per study, with an effect size mean and standard error. Build a proper bayesian model to analyze the simulated data. Then simulate publication bias (only some of the studies you simulate are likely to be published, which?), the effect of publication bias on your estimates (re-run the model on published studies, assess the difference), and use at least one technique to assess publication bias. remember to use at least one plot to visualize your results. BONUS question: do a power/precision analysis.

2.  What is the current evidence for distinctive vocal patterns in schizophrenia? Use the data from Parola et al (2020) - <https://www.dropbox.com/s/0l9ur0gaabr80a8/Matrix_MetaAnalysis_Diagnosis_updated290719.xlsx?dl=0> - focusing on pitch variability (PITCH_F0SD). Describe the data available (studies, participants). Using the model from question 1 analyze the data, visualize and report the findings: population level effect size; how well studies reflect it; influential studies, publication bias. BONUS question: add the findings from <https://www.medrxiv.org/content/10.1101/2022.04.03.22273354v2>. BONUS question: assess the effect of task on the estimates (model comparison with baseline model)

## Question 1

### Simulation

```{r}
mean_effect <- 0.4
effect_sd <- 0.4
meas_error <- 0.8

par_mean <- 20
par_sd <- 10

n <- 100

```

```{r}
sim_studies <-
  tibble(
    study_ID = seq(1:n),
    n_participants = 
        round(rtnorm(n, mean=par_mean, sd=par_sd, lower=10))
    ) 
      
  
for (i in seq(nrow(sim_studies))){
    sim_studies$study_effect[i] <- 
      rnorm(1,mean_effect,effect_sd)
    temp <- 
      rnorm(sim_studies$n_participants[i],sim_studies$study_effect[i], meas_error)
    sim_studies$mean_effect_size[i] <- 
      mean(temp)
    sim_studies$sd_effect[i] <- 
      sd(temp)
    sim_studies$standard_error[i] <-
      sim_studies$sd_effect[i]/sqrt(sim_studies$n_participants[i])
  }


```

### Bayesian model

```{r}
model_study <- bf(mean_effect_size|se(standard_error) ~1 + (1|study_ID))
```

#### Priors

```{r}
get_prior(data = sim_studies, family = gaussian, model_study)

priors <- c(
  prior(normal(0, 0.3), class=Intercept),
  prior(normal(0, 0.3), class=sd))
```

#### Model

Only priors

```{r}
model_prior <- brm(
  model_study, 
  data = sim_studies, 
  prior = priors,
  family = gaussian,
  refresh=0,
  sample_prior = 'only',
  iter=10000,
  warmup = 1000,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
)
)

pp_check(model_prior, ndraws=100)
```

#### Fitting model

```{r}
model_prior_fit <- brm(
  model_study, 
  data = sim_studies, 
  prior = priors,
  family = gaussian,
  refresh=0,
  sample_prior = TRUE,
  iter=10000,
  warmup = 1000,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
)
)

pp_check(model_prior_fit, ndraws=100)
```

```{r}
plot(model_prior_fit)
```
```{r}
summary(model_prior_fit)
```


#### Prior posterior update check
```{r}
model_posterior <- as_draws_df(model_prior_fit)

plot1 <- ggplot(model_posterior)+
  geom_histogram(aes(prior_Intercept), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on intercept')+
  xlab('intercept')


plot2 <- ggplot(model_posterior)+
  geom_histogram(aes(prior_sd_study_ID), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(sd_study_ID__Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on standard deviation of the intercept')+
  xlab('intercept')

grid.arrange(plot1, plot2)
```


### Simulation of publication bias, the effect of publication bias on our estimate and asses the publication bias (remember to visualize our results)

```{r}
for (i in seq(nrow(sim_studies))){
  sim_studies$published[i] <-
    ifelse(abs(
      sim_studies$mean_effect_size)-(2*sim_studies$standard_error)>0 
      & sim_studies$mean_effect_size[i]>0,
      rbinom(1,1,0.9), rbinom(1,1,0.1))}

sim_studies <- sim_studies %>%
  mutate(published=as.factor(published))

pub_sim_studies <- filter(sim_studies, published==1)
```

```{r}
pub_model_prior_fit <- brm(
  model_study, 
  data = pub_sim_studies, 
  prior = priors,
  family = gaussian,
  refresh=0,
  sample_prior = TRUE,
  iter=10000,
  warmup = 1000,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
)
)

pp_check(pub_model_prior_fit, ndraws=100)
```

```{r}
plot(pub_model_prior_fit)

summary(pub_model_prior_fit)

pub_posterior <- as_draws_df(pub_model_prior_fit)
```

```{r}
pub_plot1 <- ggplot(pub_posterior)+
  geom_histogram(aes(prior_Intercept), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on intercept (published)')+
  xlab('intercept')


pub_plot2 <- ggplot(pub_posterior)+
  geom_histogram(aes(prior_sd_study_ID), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(sd_study_ID__Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on standard deviation of the intercept (published)')+
  xlab('sd')


grid.arrange(pub_plot1, pub_plot2)


```
```{r}
plot3 <- ggplot()+
  geom_histogram(aes(pub_posterior$Intercept), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(model_posterior$Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('effect size with and without the un-published studis')+
  xlab('red=without un-published, green=with un-published')


plot4 <- ggplot()+
  geom_histogram(aes(pub_posterior$sd_study_ID__Intercept), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(model_posterior$sd_study_ID__Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('standard deviation of the effect size with and without the un-published studis')+
  xlab('red=without un-published, green=with un-published')

grid.arrange(plot3, plot4)
```

### BONUS: Power/precision analysis

## Question 2

```{r}
matrix_ma <- read_excel("Matrix_MetaAnalysis.xlsx")
```
### Describing the data 
```{r}

##Filtering out NA & NR
matrix_ma_filter_for_analysis <- matrix_ma %>%
  dplyr::filter(AGE_M_SZ!="NR") %>%
  dplyr::filter(AGE_M_SZ!="NA")
matrix_ma_filter_for_analysis <- matrix_ma_filter_for_analysis %>%
  dplyr::filter(AGE_SD_SZ!="NR") %>%
  dplyr::filter(AGE_SD_SZ!="NA")
matrix_ma_filter_for_analysis <- matrix_ma_filter_for_analysis %>%
  dplyr::filter(MALE_SZ!="NR") %>%
  dplyr::filter(MALE_SZ!="NA")
matrix_ma_filter_for_analysis <- matrix_ma_filter_for_analysis %>%
  dplyr::filter(FEMALE_SZ!="NR") %>%
  dplyr::filter(FEMALE_SZ!="NA")

##Filtering out NA & NR for 
matrix_ma_filter_for_analysis <- matrix_ma_filter_for_analysis %>%
  dplyr::filter(AGE_M_HC!="NR") %>%
  dplyr::filter(AGE_M_HC!="NA")
matrix_ma_filter_for_analysis <- matrix_ma_filter_for_analysis %>%
  dplyr::filter(AGE_SD_HC!="NR") %>%
  dplyr::filter(AGE_SD_HC!="NA")
matrix_ma_filter_for_analysis <- matrix_ma_filter_for_analysis %>%
  dplyr::filter(MALE_HC!="NR") %>%
  dplyr::filter(MALE_HC!="NA")
matrix_ma_filter_for_analysis <- matrix_ma_filter_for_analysis %>%
  dplyr::filter(FEMALE_HC!="NR") %>%
  dplyr::filter(FEMALE_HC!="NA")
##Making the variables numeric for SZ
matrix_ma_filter_for_analysis$AGE_M_SZ <- as.numeric(matrix_ma_filter_for_analysis$AGE_M_SZ)

matrix_ma_filter_for_analysis$AGE_SD_SZ <- as.numeric(matrix_ma_filter_for_analysis$AGE_SD_SZ)

matrix_ma_filter_for_analysis$MALE_SZ <- as.numeric(matrix_ma_filter_for_analysis$MALE_SZ)

matrix_ma_filter_for_analysis$FEMALE_SZ <- as.numeric(matrix_ma_filter_for_analysis$FEMALE_SZ)


##Making the variables numeric for HC
matrix_ma_filter_for_analysis$AGE_M_HC <- as.numeric(matrix_ma_filter_for_analysis$AGE_M_HC)

matrix_ma_filter_for_analysis$AGE_SD_HC <- as.numeric(matrix_ma_filter_for_analysis$AGE_SD_HC)

matrix_ma_filter_for_analysis$MALE_HC <- as.numeric(matrix_ma_filter_for_analysis$MALE_HC)

matrix_ma_filter_for_analysis$FEMALE_HC <- as.numeric(matrix_ma_filter_for_analysis$FEMALE_HC)


##Making a tibble  
a <- tibble(diagnosis = "SZ",
         mean_sample_size=mean(matrix_ma_filter_for_analysis$SAMPLE_SIZE_SZ),
         mean_numer_of_males=mean(matrix_ma_filter_for_analysis$MALE_SZ),
         mean_number_of_females=mean(matrix_ma_filter_for_analysis$FEMALE_SZ),
         mean_age=mean(matrix_ma_filter_for_analysis$AGE_M_SZ),
         mean_sd_age=mean(matrix_ma_filter_for_analysis$AGE_SD_SZ)
         )
  

b <- tibble(diagnosis = "HC",
         mean_sample_size=mean(matrix_ma_filter_for_analysis$SAMPLE_SIZE_HC),
         mean_numer_of_males=mean(matrix_ma_filter_for_analysis$MALE_HC),
         mean_number_of_females=mean(matrix_ma_filter_for_analysis$FEMALE_HC),
         mean_age=mean(matrix_ma_filter_for_analysis$AGE_M_HC),
         mean_sd_age=mean(matrix_ma_filter_for_analysis$AGE_SD_HC)
         )

bind_rows(a,b)
```

### Analysis 
In this analysis we are using the function escalc. The function calculates the standardized mean difference between two groups, called hedges G. The value represents the effect size and is similar to cohen's d.

the formula for g is = (x1 – x2) / √((n1-1)*s12 + (n2-1)*s22) / (n1+n2-2)

and 

the formula for d is = (x1 – x2) / √(s12 + s22) / 2

Hedges g takes the sample size of each group into account, and g = d when the two samples sizes er equal. We have therefore chosen to use hedges g to calculate the effect size of the different studies.
```{r}
matrix_pitch <- matrix_ma %>% 
  select('StudyID','Article','SAMPLE_SIZE_SZ','SAMPLE_SIZE_HC', 'PITCH_F0SD_HC_M','PITCH_F0SD_HC_SD','PITCH_F0SD_SZ_M','PITCH_F0SD_SZ_SD')

matrix_pitch <- matrix_pitch %>% 
  na.omit()

matrix_pitch <- matrix_pitch %>% 
  mutate(sample_size=(SAMPLE_SIZE_SZ+SAMPLE_SIZE_HC))

matrix_pitch <- matrix_pitch %>% 
  mutate(StudyID=as.factor(StudyID))

matrix_pitch <- matrix_pitch %>% 
  mutate(StudyID=as.numeric(StudyID))

matrix_pitch <- matrix_pitch %>% 
  mutate(StudyID=as.factor(StudyID))

matrix_pitch <- escalc('SMD', 
                       n1i=SAMPLE_SIZE_HC,
                       n2i=SAMPLE_SIZE_SZ,
                       m1i = PITCH_F0SD_HC_M, 
                       m2i=PITCH_F0SD_SZ_M,
                       sd1i = PITCH_F0SD_HC_SD, 
                       sd2i = PITCH_F0SD_SZ_SD,
                       data = matrix_pitch)

matrix_pitch <- matrix_pitch %>% 
  rename(effect_size=yi)
```

```{r}

for (i in seq(nrow(matrix_pitch))){
  matrix_pitch$sd_effect[i] <- sqrt((sum((matrix_pitch$effect_size[i] - mean(matrix_pitch$effect_size))^2))/length(matrix_pitch))
  matrix_pitch$standard_error[i] <- matrix_pitch$sd_effect[i]/sqrt(matrix_pitch$sample_size)
}


```

```{r}
model_matrix <- bf(effect_size|se(standard_error) ~1 + (1|StudyID))


get_prior(data = matrix_pitch, family = gaussian, model_matrix)

matrix_priors <- c(
  prior(normal( 0.3, 2.5), class=Intercept),
  prior(normal( 0, 2.5), class=sd))
```

#### Fitting model with only the priors
```{r}
matrix_prior_fit <- brm(
  model_matrix, 
  data = matrix_pitch, 
  prior = matrix_priors,
  family = gaussian,
  refresh=0,
  sample_prior = 'only',
  iter=10000,
  warmup = 1000,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
)
)

pp_check(matrix_prior_fit, ndraws=100)
```

#### Fitting model on data
```{r}
matrix_fit <- brm(
  model_matrix, 
  data = matrix_pitch, 
  prior = matrix_priors,
  family = gaussian,
  refresh=0,
  sample_prior = 'only',
  iter=10000,
  warmup = 1000,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
)
)

pp_check(matrix_fit)
```

```{r}
plot(matrix_fit)

summary(matrix_fit)
```
Our model gives us an estimated intercept (effect size) of 0.3 with a estimated standard deviation of 2, which is due to the effect sizes of the studies varying a lot. 
For example we have the study Cohen et al. (2014) with an effect size of -3.30 (sd=0.90, se=0.11, n=76), therefore we are running our model fit again were we exclude the study to see how influential it is on the estimates.

```{r}
excluded_matrix <- matrix_pitch %>% 
  dplyr::filter(StudyID!=6)


exclude_matrix_fit <- brm(
  model_matrix, 
  data = excluded_matrix, 
  prior = matrix_priors,
  family = gaussian,
  refresh=0,
  sample_prior = 'only',
  iter=10000,
  warmup = 1000,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
)
)

pp_check(exclude_matrix_fit)

plot(exclude_matrix_fit)

summary(exclude_matrix_fit)
```



```{r}
matrix_posterior <- as_draws_df(matrix_fit)

## we cannot get this to work and do not know why
# But we do not know if this is even necessary to include

plot1 <- ggplot(matrix_posterior)+
  geom_histogram(aes(lprior), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on intercept')+
  xlab('intercept')


plot2 <- ggplot(matrix_posterior)+
  geom_histogram(aes(prior_sd_StudyID), fill='red', color='black', alpha=0.3, bins=50)+
  geom_histogram(aes(sd_StudyID__Intercept), fill='green', color='black', alpha=0.3, bins=50)+
  theme_classic()+
  ggtitle('prior-posterior update check on standard deviation of the intercept')+
  xlab('intercept')


```

