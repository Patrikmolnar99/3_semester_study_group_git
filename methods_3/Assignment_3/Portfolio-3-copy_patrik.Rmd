---
title: "Assignment_3"
author: "Patrik Molnar"
date: '2022-11-09'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Assignment 3
```{r stup}
pacman::p_load(glue,
       tidyr,
       data.table,
       moments,
       tidybayes,
       tibble,
       cowplot,
       viridis,
       brms,
       rstan,
       cmdstanr,
       magrittr,
       gridExtra,
       grid,
       lattice,
       ggplot2,
       ggridges,
       ellipse,
       Rmisc, 
       dplyr, 
       "rmarkdown", 
       knitr)
pacman::p_load(tidyverse)
pacman::p_load(purr)
pacman::p_load(splitstackshape)
pacman::p_load(tidymodels)
```
##Part 1 - Simulating data
 
Use meta analysis reported in Parola et al (2020) to create informed simulated data 
- 100 pairs of schizophrenia and controls, each participant producing 10 repeated measures (10 trials with their speech recorded), for each recording produce 10 acoustic measures (6 from meta analysis and 4 with random noise)

- Do the same for a baseline data set including only 10 noise variables 

### seeting up variables
```{r}
###Data simulation 
n <- 100
trials <- 10

#Effect sizes definition = Informed effect mean and Skeptic effect mean
IEM <- c(-0.5,-1.26,-.74,1.89,0.25,1.3,0,0,0,0)
SEM <- rep(0,10)

#Defining individual vairability from populationd accross trials measurement error
ISD <- 1
TSD <- 0.5
E <- 0.2

```
### Simulating the true effect size for each varibale for all pairs of participants
```{r}
for (i in seq(10)){
  temp_informed <- tibble(
    ID=seq(n),
    TrueEffect = rnorm(n, IEM[i], ISD),
    Variable = paste0("V",i))
  temp_skeptic <- tibble(
    ID=seq(n),
    TrueEffect = rnorm(n, SEM[i], ISD),
    Variable = paste0("V",i))
  
  if(i==1){
    d_informed_true <- temp_informed
    d_skeptic_true <- temp_skeptic
  } else {
    d_informed_true <-  rbind(d_informed_true, temp_informed)
    d_skeptic_true <- rbind(d_skeptic_true, temp_skeptic)
  }
}
```
### Creating one row per trial 
```{r}
d_trial <- tibble(expand_grid(ID=seq(n), Trial = seq(trials), Group = c("Schizophrenia", "Control")))

d_informed <- merge(d_informed_true, d_trial)
d_skeptic <- merge(d_skeptic_true, d_trial)

for ( i in seq(nrow(d_informed))){
  d_informed$measurement[i] <- ifelse(d_informed$Group[i]=="Schizophrenia",
                                      rnorm(1, rnorm(1, d_informed$TrueEffect[i]/2, TSD), E),
                                      rnorm(1, rnorm(1, (-d_informed$TrueEffect[i])/2, TSD), E))
  
  d_skeptic$measurement[i] <- ifelse(d_skeptic$Group[i]=="Schizophrenia",
                                      rnorm(1, rnorm(1, d_skeptic$TrueEffect[i]/2, TSD), E),
                                      rnorm(1, rnorm(1, (-d_skeptic$TrueEffect[i])/2, TSD), E))
}


```
### Transforming the dataframe to a wide format based on the variable
```{r}
d_informed_wide <- d_informed %>% 
  mutate(TrueEffect=NULL) %>% 
  pivot_wider(names_from = Variable,
              values_from = measurement)
d_skeptic_wide <- d_skeptic %>% 
  mutate(TrueEffect=NULL) %>% 
  pivot_wider(names_from = Variable,
              values_from = measurement)

for (i in d_informed_wide$ID){
  
  filter(Group == "Schizophrenia")%>%
    d_informed_wide$ID+100
}
```


### Visualizing the simulated informed data
```{r}
plot1 <- d_informed_wide %>% 
  ggplot(aes(x = V1, color = Group))+
  geom_density()

plot2 <- d_informed_wide %>% 
  ggplot(aes(x = V2, color = Group))+
  geom_density()

plot3 <- d_informed_wide %>% 
  ggplot(aes(x = V3, color = Group))+
  geom_density()

plot4 <- d_informed_wide %>% 
  ggplot(aes(x = V4, color = Group))+
  geom_density()

plot5 <- d_informed_wide %>% 
  ggplot(aes(x = V5, color = Group))+
  geom_density()

plot6 <- d_informed_wide %>% 
  ggplot(aes(x = V6, color = Group))+
  geom_density()

plot7 <- d_informed_wide %>% 
  ggplot(aes(x = V7, color = Group))+
  geom_density()

plot8 <- d_informed_wide %>% 
  ggplot(aes(x = V8, color = Group))+
  geom_density()

plot9 <- d_informed_wide %>% 
  ggplot(aes(x = V9, color = Group))+
  geom_density()

plot10 <- d_informed_wide %>% 
  ggplot(aes(x = V10, color = Group))+
  geom_density()

cowplot::plot_grid(plot1, plot2, plot3, plot4, plot5, plot6, plot7, plot8, plot9, plot10, 
          labels = c("v1", "v2", "v3",'v4','v5','v6','v7','v8','v9','v10'),
          ncol = 5, nrow = 2)


```

### Visualizing the simulated data for skeptical data frame
```{r}
plot1_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V1, color = Group))+
  geom_density()

plot2_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V2, color = Group))+
  geom_density()

plot3_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V3, color = Group))+
  geom_density()

plot4_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V4, color = Group))+
  geom_density()

plot5_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V5, color = Group))+
  geom_density()

plot6_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V6, color = Group))+
  geom_density()

plot7_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V7, color = Group))+
  geom_density()

plot8_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V8, color = Group))+
  geom_density()

plot9_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V9, color = Group))+
  geom_density()

plot10_s <- d_skeptic_wide %>% 
  ggplot(aes(x = V10, color = Group))+
  geom_density()

cowplot::plot_grid(plot1_s, plot2_s, plot3_s, plot4_s, plot5_s, plot6_s, plot7_s, plot8_s, plot9_s, plot10_s, 
          labels = c("v1", "v2", "v3",'v4','v5','v6','v7','v8','v9','v10'),
          ncol = 5, nrow = 2)


```

##Part 2 - Machine larning pipeline on simulated data 
Build a machine leaning pipeline (separately on the 2 datasets)
- create a data budget (e.g., balanced training and test sets)
pree-process the data (e.g., scaling the features)
- fit and assess a classification algorithm on the training data (e.g., bayesian multilevel logistic regression)
- assess performance on the test set
- discuss whether performance and feature importance is as expected

### Informed dataset
#### Data budget and pree-processing (scaling)
```{r}
##Machine Learning pipeline
TestID <- sample(seq(n),20)

train_informed <- d_informed_wide %>%
  subset(!(ID%in% TestID))
test_informed <- d_informed_wide %>% subset(ID%in%TestID)

train_skeptic <- d_skeptic_wide %>%
  subset(!(ID%in% TestID))
test_skeptic <- d_skeptic_wide %>% subset(ID%in%TestID)

train_informed$ID <- as.factor(train_informed$ID)
train_skeptic$ID <- as.factor(train_skeptic$ID)

train_informed$Trial <- as.factor(train_informed$Trial)
train_skeptic$Trial <- as.factor(train_skeptic$Trial)

##Splitting the data using stratified, which also take into consideration stratification of the f.e. gender

# set.seed(666)
# stratified(d_informed_wide, "Group", 0.8)
# 
# ?stratified


#Scaling
rec_informed <- train_informed %>% 
  recipe(Group~.) %>% 
  step_scale(all_numeric()) %>% 
  step_center(all_numeric()) %>% 
  prep(train_informed, retain=TRUE)

rec_skeptic <- train_skeptic %>% 
  recipe(Group~.) %>% 
  step_scale(all_numeric()) %>% 
  step_center(all_numeric()) %>% 
  prep(train_skeptic, retain=TRUE)

train_informed_s <- juice(rec_informed)
test_informed_s <- bake(rec_informed, new_data = test_informed)

train_skeptic_s <- juice(rec_skeptic)
test_skeptic_s <- bake(rec_skeptic, new_data = test_skeptic)

#Ask ricardo about the ID scaling
```
#### Visual inspection of the data
```{r}
#Plotting
plot_i2 <- ggplot(train_informed, aes(V2, Group, colour=Group))+
  geom_point()+
  geom_smooth(method = "glm", se=FALSE)+
  theme_bw()+
  ggtitle("informed")

plot_s2 <- ggplot(train_skeptic, aes(V2, Group, colour=Group))+
  geom_point()+
  geom_smooth(method = "glm", se=FALSE)+
  theme_bw()+
  ggtitle("sceptical")

plot_i3 <- ggplot(train_informed, aes(V3, Group, colour=Group))+
  geom_point()+
  geom_smooth(method = "glm", se=FALSE)+
  theme_bw()+
  ggtitle("informed")

plot_s3 <- ggplot(train_skeptic, aes(V3, Group, colour=Group))+
  geom_point()+
  geom_smooth(method = "glm", se=FALSE)+
  theme_bw()+
  ggtitle("sceptical")

plot_i4 <- ggplot(train_informed, aes(V4, Group, colour=Group))+
  geom_point()+
  geom_smooth(method = "glm", se=FALSE)+
  theme_bw()+
  ggtitle("informed")

plot_s4 <- ggplot(train_skeptic, aes(V4, Group, colour=Group))+
  geom_point()+
  geom_smooth(method = "glm", se=FALSE)+
  theme_bw()+
  ggtitle("sceptical")

plot_i6 <- ggplot(train_informed, aes(V6, Group, colour=Group))+
  geom_point()+
  geom_smooth(method = "glm", se=FALSE)+
  theme_bw()+
  ggtitle("informed")

plot_s6 <- ggplot(train_skeptic, aes(V6, Group, colour=Group))+
  geom_point()+
  geom_smooth(method = "glm", se=FALSE)+
  theme_bw()+
  ggtitle("sceptical")

plot_grid(plot_i2, plot_s2, plot_i3, plot_s3, plot_i4, plot_s4, plot_i6, plot_s6)

#Make the distribution 
```
####fit and asses a classification algorithm on training data (Baysian)

```{r}
##Setting up the model
PR_f0 <-bf(Group~1+V1+V2+V3+V4+V5+V6+V7+V8+V9+V10)

PR_f1 <-bf(Group~1+V1+V2+V3+V4+V5+V6+V7+V8+V9+V10+(1|))

get_prior(PR_f0, train_informed, family = bernoulli)

get_prior(PR_f1, train_informed, family = bernoulli)
```
```{r}
##setting the priors
PR_p0 <- c(
  prior(normal(0,1), class=Intercept),
  prior(normal(0, 0.3), class=b, coef="V1"),
  prior(normal(0, 0.3), class=b, coef="V2"),
  prior(normal(0, 0.3), class=b, coef="V3"),
  prior(normal(0, 0.3), class=b, coef="V4"),
  prior(normal(0, 0.3), class=b, coef="V5"),
  prior(normal(0, 0.3), class=b, coef="V6"),
  prior(normal(0, 0.3), class=b, coef="V7"),
  prior(normal(0, 0.3), class=b, coef="V8"),
  prior(normal(0, 0.3), class=b, coef="V9"),
  prior(normal(0, 0.3), class=b, coef="V10")
  
)

PR_p1 <- c(
  prior(normal(0,1), class=Intercept),
  prior(normal(0, 0.3), class=b, coef="V1"),
  prior(normal(0, 0.3), class=b, coef="V2"),
  prior(normal(0, 0.3), class=b, coef="V3"),
  prior(normal(0, 0.3), class=b, coef="V4"),
  prior(normal(0, 0.3), class=b, coef="V5"),
  prior(normal(0, 0.3), class=b, coef="V6"),
  prior(normal(0, 0.3), class=b, coef="V7"),
  prior(normal(0, 0.3), class=b, coef="V8"),
  prior(normal(0, 0.3), class=b, coef="V9"),
  prior(normal(0, 0.3), class=b, coef="V10")
  
)
```

```{r}
##Model fit on priors
pr_m0 <- brm(
  PR_f0, 
  data = train_informed_s, 
  prior = PR_p0,
  family = bernoulli,
  refresh=0,
  sample_prior = 'only',
  iter=6000,
  warmup = 2500,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 4,
  cores = 4,
  control = list(
    adapt_delta = 0.9,
    max_treedepth = 20)
)


pp_check(pr_m0)
```

```{r}
##Model fit on data
pr_m0_fit <- brm(
  PR_f0, 
  data = train_informed_s, 
  prior = PR_p0,
  family = bernoulli,
  refresh=0,
  sample_prior = TRUE,
  iter=6000,
  warmup = 2500,
  backend = "cmdstanr",
  threads = threading(2),
  chains = 4,
  cores = 4,
  control = list(
    adapt_delta = 0.9,
    max_treedepth = 20)
)

pp_check(pr_m0_fit)

plot(pr_m0_fit)

summary(pr_m0_fit)

```
```{r}
##Model interpretation
PR_m0

```

#### Asses performance on test data

#### Discuss whether performance and feature importance is as expected